{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d20948-4efd-4d15-94de-27475b203c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b591336-2e39-4c33-94be-ecd9d37b5679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test\n",
      "Processed 11 pdf files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 07:28:13.721307: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-19 07:28:13.727195: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734593293.735615      88 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734593293.738082      88 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-19 07:28:13.747130: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "DATA_PATH = \"./test\"\n",
    "DB_PATH = \"./vectorstores/db/\"\n",
    "\n",
    "def create_vector_db():\n",
    "    print(DATA_PATH)\n",
    "    loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    documents = loader.load()\n",
    "\n",
    "    print(f\"Processed {len(documents)} pdf files\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    embedding_function = HuggingFaceEmbeddings(\n",
    "        model_name='BAAI/bge-m3'\n",
    "    )\n",
    "\n",
    "    vectorstore = Chroma.from_documents(documents=texts, embedding=embedding_function, persist_directory=DB_PATH)\n",
    "    # vectorstore.persist()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_vector_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480f336a-7f3b-4531-a0b6-bf50a083e275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import chainlit as cl\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "\n",
    "QA_CHAIN_PROMPT = hub.pull('rlm/rag-prompt-mistral')\n",
    "\n",
    "def load_llm():\n",
    "    llm = Ollama(\n",
    "        model=\"llama3\",\n",
    "        verbose=True,\n",
    "        callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "def retrieval_qa_chain(llm, vectorstore):\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "def qa_bot():\n",
    "    llm = load_llm()\n",
    "    DB_PATH=\"vectorstores/db/\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='BAAI/bge-m3')\n",
    "    vectorstore = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)\n",
    "    qa = retrieval_qa_chain(llm, vectorstore)\n",
    "    return qa\n",
    "\n",
    "# 새로운 채팅 세션이 시작될 때 호출되는 함수를 정의\n",
    "@cl.on_chat_start\n",
    "async def start():\n",
    "    chain = qa_bot()\n",
    "    msg = cl.Message(contents=\"Firing up the research into bot...\")\n",
    "    await msg.send()\n",
    "    msg.content = \"Hi, welcome to the research info bot. What is your query?\"\n",
    "    await msg.update()\n",
    "    cl.user_session.set(\"chain\", chain)\n",
    "\n",
    "# 사용자가 보낸 메시지를 수신할 때 호출되는 함수\n",
    "@cl.on_message\n",
    "async def main(message):\n",
    "    chain = cl.cl.user_session.get(\"chain\")\n",
    "    cb = cl.AsyncLangchainCallbackHandler(\n",
    "        stream_final_answer=True,\n",
    "        answer_prefix_tokens=[\"FINAL\", \"ANSWER\"]\n",
    "    )\n",
    "    cb.answer_reached=True\n",
    "\n",
    "    res = await chain.acall(message.content, callbacks=[cb])\n",
    "    print(f\"response: {res}\")\n",
    "\n",
    "    answer = res[\"result\"]\n",
    "    answer = answer.replace(\".\", \".\\n\")\n",
    "    sources = res[\"source_documents\"]\n",
    "\n",
    "    if sources:\n",
    "        answer += f\"\\nSources: \" + str(str(sources))\n",
    "    else:\n",
    "        answer += f\"\\nNo Sources found\"\n",
    "\n",
    "    await cl.Message(content=answer).send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d384b4-9b9e-4e23-9a8a-6641a7742375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linting ta.json...\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_one'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.running'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_other'\n",
      "❌ Missing key: 'components.molecules.detailsButton.used'\n",
      "\n",
      "Linting te.json...\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_one'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.running'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_other'\n",
      "❌ Missing key: 'components.molecules.detailsButton.used'\n",
      "\n",
      "Linting gu.json...\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_one'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.running'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_other'\n",
      "❌ Missing key: 'components.molecules.detailsButton.used'\n",
      "\n",
      "Linting mr.json...\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_one'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.running'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_other'\n",
      "❌ Missing key: 'components.molecules.detailsButton.used'\n",
      "\n",
      "Linting ml.json...\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_one'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.running'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_other'\n",
      "❌ Missing key: 'components.molecules.detailsButton.used'\n",
      "\n",
      "Linting hi.json...\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_one'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.running'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_other'\n",
      "❌ Missing key: 'components.molecules.detailsButton.used'\n",
      "\n",
      "Linting kn.json...\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_one'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.running'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_other'\n",
      "❌ Missing key: 'components.molecules.detailsButton.used'\n",
      "\n",
      "Linting zh-CN.json...\n",
      "✅ No errors found in zh-CN.json\n",
      "\n",
      "Linting he-IL.json...\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_one'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.running'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_other'\n",
      "❌ Missing key: 'components.molecules.detailsButton.used'\n",
      "\n",
      "Linting bn.json...\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_one'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.running'\n",
      "⚠️ Extra key: 'components.molecules.detailsButton.took_other'\n",
      "❌ Missing key: 'components.molecules.detailsButton.used'\n",
      "\n",
      "Linting en-US.json...\n",
      "✅ No errors found in en-US.json\n"
     ]
    }
   ],
   "source": [
    "!chainlit lint-translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383176d0-8832-46e0-9f9a-843b6e3a2abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
